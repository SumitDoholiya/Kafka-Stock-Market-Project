# Kafka-Stock-Market-Project

# ðŸ“ˆ Stock Market Real-Time Data Engineering Project

This project simulates a real-time data engineering pipeline using Apache Kafka and AWS services. It demonstrates how stock market data can be ingested, streamed, stored, cataloged, and queried in real time.

## ðŸš€ Project Overview

The goal of this project is to build an end-to-end streaming architecture that mimics a stock market data feed, processes it in real time using Kafka, stores the data in Amazon S3, and allows analytics using AWS Athena.

## ðŸ”§ Tech Stack

- **Apache Kafka** â€“ For real-time data streaming
- **Python** â€“ Kafka producer & consumer scripts
- **AWS S3** â€“ Data lake to store the stream
- **AWS Glue** â€“ For data cataloging and ETL jobs
- **AWS Athena** â€“ To run SQL queries on the stored data
- **Docker (optional)** â€“ For local Kafka setup

## ðŸ“Œ Features

- Real-time streaming of stock market data
- Kafka producer simulates a live stock ticker
- Kafka consumer writes incoming data to AWS S3 in JSON/CSV format
- AWS Glue crawler automatically catalogs S3 data
- Serverless querying using AWS Athena
- Scalable architecture following best practices in data engineering

## ðŸ“‚ Project Structure

```bash
.
â”œâ”€â”€ kafka_producer.py         # Sends real-time stock data to Kafka
â”œâ”€â”€ kafka_consumer.py         # Reads from Kafka and uploads to S3
â”œâ”€â”€ stock_data/               # Sample data folder
â”œâ”€â”€ glue_catalog_config/      # AWS Glue configuration
â”œâ”€â”€ athena_queries/           # Sample SQL queries
â””â”€â”€ README.md
